====================================================================================================
> training arguments:
>>> if_test: 0
>>> run_model: cot
>>> k_label: 2
>>> dataset: pp_tweets
>>> model_type: vanilla
>>> loss_type: rsgan
>>> mu_type: ragan
>>> eval_type: Ra
>>> d_type: Ra
>>> if_real_data: 0
>>> cuda: 1
>>> device: 0
>>> devices: 0
>>> shuffle: 0
>>> gen_init: normal
>>> dis_init: normal
>>> n_parent: 1
>>> eval_b_num: 8
>>> lambda_fq: 1.0
>>> lambda_fd: 0.0
>>> d_out_mean: True
>>> freeze_dis: False
>>> freeze_clas: False
>>> use_all_real_fake: False
>>> use_population: False
>>> samples_num: 10000
>>> vocab_size: 5000
>>> mle_epoch: 0
>>> clas_pre_epoch: 10
>>> adv_epoch: 20000
>>> inter_epoch: 15
>>> batch_size: 64
>>> max_seq_len: 20
>>> start_letter: 1
>>> padding_idx: 0
>>> gen_lr: 0.01
>>> gen_adv_lr: 0.0001
>>> dis_lr: 0.0001
>>> clip_norm: 5.0
>>> pre_log_step: 10
>>> adv_log_step: 100
>>> train_data: dataset/pp_tweets.txt
>>> test_data: dataset/testdata/pp_tweets_test.txt
>>> temp_adpt: exp
>>> evo_temp_step: 1
>>> temperature: 1
>>> ora_pretrain: 1
>>> gen_pretrain: 0
>>> dis_pretrain: 0
>>> adv_g_step: 1
>>> rollout_num: 16
>>> gen_embed_dim: 32
>>> gen_hidden_dim: 32
>>> goal_size: 16
>>> step_size: 4
>>> mem_slots: 1
>>> num_heads: 2
>>> head_size: 256
>>> d_step: 5
>>> d_epoch: 3
>>> adv_d_step: 1
>>> adv_d_epoch: 3
>>> dis_embed_dim: 64
>>> dis_hidden_dim: 64
>>> num_rep: 64
>>> use_nll_oracle: 1
>>> use_nll_gen: 1
>>> use_nll_div: 1
>>> use_bleu: 1
>>> use_self_bleu: 1
>>> use_clas_acc: True
>>> use_ppl: 0
>>> log_file: log/log_0329_2120_19.txt
>>> save_root: save/20240329/pp_tweets/cot_vanilla_dt-Ra_lt-rsgan_mt-ra_et-Ra_sl20_temp1_lfd0.0_T0329_2120_19/
>>> signal_file: run_signal.txt
>>> tips: CoT experiments
====================================================================================================
Starting Generator MLE Training...
Starting Adversarial Training...
[ADV]: epoch = 0, NLL_oracle = 11.1403, NLL_gen = 8.5174, NLL_div = 8.517
[ADV]: epoch = 100, NLL_oracle = 10.1788, NLL_gen = 7.9088, NLL_div = 7.9573
[ADV]: epoch = 200, NLL_oracle = 10.0926, NLL_gen = 7.8751, NLL_div = 7.9007
[ADV]: epoch = 300, NLL_oracle = 10.0023, NLL_gen = 7.8488, NLL_div = 7.8202
[ADV]: epoch = 400, NLL_oracle = 10.0291, NLL_gen = 7.8266, NLL_div = 7.8403
[ADV]: epoch = 500, NLL_oracle = 9.9991, NLL_gen = 7.8113, NLL_div = 7.8159
[ADV]: epoch = 600, NLL_oracle = 9.9469, NLL_gen = 7.7699, NLL_div = 7.7612
[ADV]: epoch = 700, NLL_oracle = 9.933, NLL_gen = 7.7522, NLL_div = 7.7714
[ADV]: epoch = 800, NLL_oracle = 9.851, NLL_gen = 7.7225, NLL_div = 7.6758
[ADV]: epoch = 900, NLL_oracle = 9.8707, NLL_gen = 7.6835, NLL_div = 7.7314
[ADV]: epoch = 1000, NLL_oracle = 9.7913, NLL_gen = 7.6529, NLL_div = 7.6275
[ADV]: epoch = 1100, NLL_oracle = 9.7686, NLL_gen = 7.6192, NLL_div = 7.621
[ADV]: epoch = 1200, NLL_oracle = 9.709, NLL_gen = 7.5806, NLL_div = 7.5703
[ADV]: epoch = 1300, NLL_oracle = 9.6675, NLL_gen = 7.539, NLL_div = 7.5326
[ADV]: epoch = 1400, NLL_oracle = 9.6585, NLL_gen = 7.4994, NLL_div = 7.5312
[ADV]: epoch = 1500, NLL_oracle = 9.5926, NLL_gen = 7.4708, NLL_div = 7.4715
[ADV]: epoch = 1600, NLL_oracle = 9.5699, NLL_gen = 7.4183, NLL_div = 7.4478
[ADV]: epoch = 1700, NLL_oracle = 9.5411, NLL_gen = 7.3735, NLL_div = 7.4275
[ADV]: epoch = 1800, NLL_oracle = 9.4961, NLL_gen = 7.3525, NLL_div = 7.3555
[ADV]: epoch = 1900, NLL_oracle = 9.4967, NLL_gen = 7.3145, NLL_div = 7.3565
[ADV]: epoch = 2000, NLL_oracle = 9.4363, NLL_gen = 7.2891, NLL_div = 7.2937
[ADV]: epoch = 2100, NLL_oracle = 9.4205, NLL_gen = 7.2337, NLL_div = 7.2929
