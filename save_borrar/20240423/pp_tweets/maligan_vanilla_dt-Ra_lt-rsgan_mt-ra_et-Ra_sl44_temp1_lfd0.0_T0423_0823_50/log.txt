====================================================================================================
> training arguments:
>>> if_test: 0
>>> run_model: maligan
>>> k_label: 2
>>> dataset: pp_tweets
>>> model_type: vanilla
>>> loss_type: rsgan
>>> mu_type: ragan
>>> eval_type: Ra
>>> d_type: Ra
>>> if_real_data: 1
>>> cuda: 1
>>> device: 0
>>> devices: 0
>>> shuffle: 0
>>> gen_init: normal
>>> dis_init: uniform
>>> n_parent: 1
>>> eval_b_num: 8
>>> lambda_fq: 1.0
>>> lambda_fd: 0.0
>>> d_out_mean: True
>>> freeze_dis: False
>>> freeze_clas: False
>>> use_all_real_fake: False
>>> use_population: False
>>> samples_num: 10000
>>> vocab_size: 21096
>>> mle_epoch: 80
>>> clas_pre_epoch: 10
>>> adv_epoch: 200
>>> inter_epoch: 15
>>> batch_size: 64
>>> max_seq_len: 44
>>> start_letter: 1
>>> padding_idx: 0
>>> gen_lr: 0.01
>>> gen_adv_lr: 0.0001
>>> dis_lr: 0.0001
>>> clip_norm: 5.0
>>> pre_log_step: 10
>>> adv_log_step: 1
>>> train_data: dataset/pp_tweets.txt
>>> test_data: dataset/testdata/pp_tweets_test.txt
>>> temp_adpt: exp
>>> evo_temp_step: 1
>>> temperature: 1
>>> ora_pretrain: 1
>>> gen_pretrain: 0
>>> dis_pretrain: 0
>>> adv_g_step: 50
>>> rollout_num: 16
>>> gen_embed_dim: 32
>>> gen_hidden_dim: 32
>>> goal_size: 16
>>> step_size: 4
>>> mem_slots: 1
>>> num_heads: 2
>>> head_size: 256
>>> d_step: 4
>>> d_epoch: 2
>>> adv_d_step: 1
>>> adv_d_epoch: 3
>>> dis_embed_dim: 64
>>> dis_hidden_dim: 64
>>> num_rep: 64
>>> use_nll_oracle: 1
>>> use_nll_gen: 1
>>> use_nll_div: 1
>>> use_bleu: 1
>>> use_self_bleu: 1
>>> use_clas_acc: True
>>> use_ppl: 0
>>> log_file: log/log_0423_0823_50.txt
>>> save_root: save/20240423/pp_tweets/maligan_vanilla_dt-Ra_lt-rsgan_mt-ra_et-Ra_sl44_temp1_lfd0.0_T0423_0823_50/
>>> signal_file: run_signal.txt
>>> tips: MaliGAN experiments
====================================================================================================
Starting Generator MLE Training...
[MLE-GEN] epoch 0 : pre_loss = 3.9913, BLEU-[2, 3, 4, 5] = [0.179, 0.105, 0.085, 0.077], NLL_gen = 2.9323, NLL_div = 2.9682, Self-BLEU-[2, 3, 4] = [0.18, 0.107, 0.087], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 10 : pre_loss = 2.2109, BLEU-[2, 3, 4, 5] = [0.358, 0.146, 0.094, 0.076], NLL_gen = 2.1279, NLL_div = 2.476, Self-BLEU-[2, 3, 4] = [0.344, 0.135, 0.08], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 20 : pre_loss = 1.7060, BLEU-[2, 3, 4, 5] = [0.421, 0.175, 0.105, 0.08], NLL_gen = 1.6759, NLL_div = 1.8949, Self-BLEU-[2, 3, 4] = [0.453, 0.195, 0.13], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 30 : pre_loss = 1.4657, BLEU-[2, 3, 4, 5] = [0.506, 0.218, 0.13, 0.094], NLL_gen = 1.4491, NLL_div = 1.8071, Self-BLEU-[2, 3, 4] = [0.475, 0.201, 0.122], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 40 : pre_loss = 1.3489, BLEU-[2, 3, 4, 5] = [0.538, 0.251, 0.152, 0.11], NLL_gen = 1.3306, NLL_div = 1.6094, Self-BLEU-[2, 3, 4] = [0.475, 0.191, 0.109], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 50 : pre_loss = 1.2782, BLEU-[2, 3, 4, 5] = [0.56, 0.265, 0.164, 0.122], NLL_gen = 1.2548, NLL_div = 1.5103, Self-BLEU-[2, 3, 4] = [0.56, 0.26, 0.153], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 60 : pre_loss = 1.2282, BLEU-[2, 3, 4, 5] = [0.571, 0.29, 0.177, 0.124], NLL_gen = 1.2046, NLL_div = 1.4749, Self-BLEU-[2, 3, 4] = [0.565, 0.259, 0.148], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 70 : pre_loss = 1.1906, BLEU-[2, 3, 4, 5] = [0.543, 0.265, 0.162, 0.119], NLL_gen = 1.1726, NLL_div = 1.4257, Self-BLEU-[2, 3, 4] = [0.565, 0.266, 0.154], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 79 : pre_loss = 1.1719, BLEU-[2, 3, 4, 5] = [0.558, 0.272, 0.167, 0.12], NLL_gen = 1.1529, NLL_div = 1.402, Self-BLEU-[2, 3, 4] = [0.576, 0.273, 0.158], [PPL-F, PPL-R] = 0
Starting Discriminator Training...
[MLE-DIS] d_step 0: d_loss = 0.6463, train_acc = 0.6183,
[MLE-DIS] d_step 1: d_loss = 0.5088, train_acc = 0.7422,
[MLE-DIS] d_step 2: d_loss = 0.3315, train_acc = 0.8673,
[MLE-DIS] d_step 3: d_loss = 0.1976, train_acc = 0.9253,
Starting Adversarial Training...
Initial generator: BLEU-[2, 3, 4, 5] = [0.578, 0.285, 0.171, 0.123], NLL_gen = 1.1529, NLL_div = 1.3877, Self-BLEU-[2, 3, 4] = [0.592, 0.284, 0.164], [PPL-F, PPL-R] = 0
-----
ADV EPOCH 0
-----
[ADV-GEN]: g_loss = -276.9594, BLEU-[2, 3, 4, 5] = [0.525, 0.286, 0.191, 0.15], NLL_gen = 1.3875, NLL_div = 0.7981, Self-BLEU-[2, 3, 4] = [0.48, 0.266, 0.183], [PPL-F, PPL-R] = 0
[ADV-DIS] d_step 0: d_loss = 0.0965, train_acc = 0.9651,
-----
ADV EPOCH 1
-----
[ADV-GEN]: g_loss = -430.1954, BLEU-[2, 3, 4, 5] = [0.66, 0.464, 0.375, 0.257], NLL_gen = 1.4958, NLL_div = 0.6016, Self-BLEU-[2, 3, 4] = [0.67, 0.516, 0.454], [PPL-F, PPL-R] = 0
[ADV-DIS] d_step 0: d_loss = 0.0518, train_acc = 0.9815,
-----
ADV EPOCH 2
-----
[ADV-GEN]: g_loss = -191.7991, BLEU-[2, 3, 4, 5] = [0.653, 0.426, 0.321, 0.222], NLL_gen = 1.6181, NLL_div = 0.6187, Self-BLEU-[2, 3, 4] = [0.701, 0.517, 0.416], [PPL-F, PPL-R] = 0
[ADV-DIS] d_step 0: d_loss = 0.0466, train_acc = 0.9823,
-----
ADV EPOCH 3
-----
[ADV-GEN]: g_loss = -469.6270, BLEU-[2, 3, 4, 5] = [0.875, 0.417, 0.282, 0.224], NLL_gen = 1.8046, NLL_div = 0.1255, Self-BLEU-[2, 3, 4] = [0.891, 0.431, 0.293], [PPL-F, PPL-R] = 0
[ADV-DIS] d_step 0: d_loss = 0.0296, train_acc = 0.9886,
-----
ADV EPOCH 4
-----
[ADV-GEN]: g_loss = -183.7808, BLEU-[2, 3, 4, 5] = [0.999, 0.997, 0.56, 0.397], NLL_gen = 2.1098, NLL_div = 0.0064, Self-BLEU-[2, 3, 4] = [0.996, 0.995, 0.56], [PPL-F, PPL-R] = 0
[ADV-DIS] d_step 0: d_loss = 0.0029, train_acc = 0.9990,
-----
ADV EPOCH 5
-----
