====================================================================================================
> training arguments:
>>> if_test: 0
>>> run_model: seqgan
>>> k_label: 2
>>> dataset: emnlp_news
>>> model_type: vanilla
>>> loss_type: rsgan
>>> mu_type: ragan
>>> eval_type: Ra
>>> d_type: Ra
>>> if_real_data: 1
>>> cuda: 1
>>> device: 0
>>> devices: 0
>>> shuffle: 0
>>> gen_init: normal
>>> dis_init: uniform
>>> n_parent: 1
>>> eval_b_num: 8
>>> lambda_fq: 1.0
>>> lambda_fd: 0.0
>>> d_out_mean: True
>>> freeze_dis: False
>>> freeze_clas: False
>>> use_all_real_fake: False
>>> use_population: False
>>> samples_num: 10000
>>> vocab_size: 5256
>>> mle_epoch: 120
>>> clas_pre_epoch: 10
>>> adv_epoch: 200
>>> inter_epoch: 15
>>> batch_size: 64
>>> max_seq_len: 51
>>> start_letter: 1
>>> padding_idx: 0
>>> gen_lr: 0.01
>>> gen_adv_lr: 0.0001
>>> dis_lr: 0.0001
>>> clip_norm: 5.0
>>> pre_log_step: 10
>>> adv_log_step: 1
>>> train_data: dataset/emnlp_news.txt
>>> test_data: dataset/testdata/emnlp_news_test.txt
>>> temp_adpt: exp
>>> evo_temp_step: 1
>>> temperature: 1
>>> ora_pretrain: 1
>>> gen_pretrain: 0
>>> dis_pretrain: 0
>>> adv_g_step: 1
>>> rollout_num: 16
>>> gen_embed_dim: 32
>>> gen_hidden_dim: 32
>>> goal_size: 16
>>> step_size: 4
>>> mem_slots: 1
>>> num_heads: 2
>>> head_size: 256
>>> d_step: 5
>>> d_epoch: 3
>>> adv_d_step: 4
>>> adv_d_epoch: 2
>>> dis_embed_dim: 64
>>> dis_hidden_dim: 64
>>> num_rep: 64
>>> use_nll_oracle: 1
>>> use_nll_gen: 1
>>> use_nll_div: 1
>>> use_bleu: 1
>>> use_self_bleu: 1
>>> use_clas_acc: True
>>> use_ppl: 0
>>> log_file: log/log_0330_1038_55.txt
>>> save_root: save/20240330/emnlp_news/seqgan_vanilla_dt-Ra_lt-rsgan_mt-ra_et-Ra_sl51_temp1_lfd0.0_T0330_1038_55/
>>> signal_file: run_signal.txt
>>> tips: SeqGAN experiments
====================================================================================================
Starting Generator MLE Training...
[MLE-GEN] epoch 0 : pre_loss = 2.7290, BLEU-[2, 3, 4, 5] = [0.799, 0.506, 0.263, 0.143], NLL_gen = 2.5313, NLL_div = 2.6536, Self-BLEU-[2, 3, 4] = [0.841, 0.56, 0.303], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 10 : pre_loss = 2.4121, BLEU-[2, 3, 4, 5] = [0.811, 0.513, 0.269, 0.145], NLL_gen = 2.4166, NLL_div = 2.5541, Self-BLEU-[2, 3, 4] = [0.845, 0.558, 0.293], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 20 : pre_loss = 2.4016, BLEU-[2, 3, 4, 5] = [0.828, 0.537, 0.294, 0.157], NLL_gen = 2.4062, NLL_div = 2.5216, Self-BLEU-[2, 3, 4] = [0.853, 0.572, 0.317], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 30 : pre_loss = 2.3976, BLEU-[2, 3, 4, 5] = [0.827, 0.529, 0.28, 0.15], NLL_gen = 2.4036, NLL_div = 2.5148, Self-BLEU-[2, 3, 4] = [0.851, 0.564, 0.304], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 40 : pre_loss = 2.3959, BLEU-[2, 3, 4, 5] = [0.825, 0.535, 0.284, 0.149], NLL_gen = 2.4008, NLL_div = 2.5177, Self-BLEU-[2, 3, 4] = [0.854, 0.58, 0.321], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 50 : pre_loss = 2.3940, BLEU-[2, 3, 4, 5] = [0.821, 0.528, 0.285, 0.157], NLL_gen = 2.4007, NLL_div = 2.5237, Self-BLEU-[2, 3, 4] = [0.846, 0.56, 0.297], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 60 : pre_loss = 2.3929, BLEU-[2, 3, 4, 5] = [0.819, 0.528, 0.279, 0.151], NLL_gen = 2.3997, NLL_div = 2.5566, Self-BLEU-[2, 3, 4] = [0.856, 0.589, 0.329], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 70 : pre_loss = 2.3904, BLEU-[2, 3, 4, 5] = [0.827, 0.539, 0.295, 0.16], NLL_gen = 2.3973, NLL_div = 2.5614, Self-BLEU-[2, 3, 4] = [0.857, 0.589, 0.33], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 80 : pre_loss = 2.3882, BLEU-[2, 3, 4, 5] = [0.822, 0.537, 0.286, 0.157], NLL_gen = 2.395, NLL_div = 2.5392, Self-BLEU-[2, 3, 4] = [0.852, 0.576, 0.315], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 90 : pre_loss = 2.3882, BLEU-[2, 3, 4, 5] = [0.814, 0.523, 0.281, 0.152], NLL_gen = 2.3944, NLL_div = 2.5187, Self-BLEU-[2, 3, 4] = [0.853, 0.58, 0.319], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 100 : pre_loss = 2.3877, BLEU-[2, 3, 4, 5] = [0.827, 0.533, 0.286, 0.157], NLL_gen = 2.3948, NLL_div = 2.4979, Self-BLEU-[2, 3, 4] = [0.851, 0.575, 0.308], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 110 : pre_loss = 2.3868, BLEU-[2, 3, 4, 5] = [0.82, 0.521, 0.263, 0.141], NLL_gen = 2.3941, NLL_div = 2.5562, Self-BLEU-[2, 3, 4] = [0.849, 0.57, 0.31], [PPL-F, PPL-R] = 0
[MLE-GEN] epoch 119 : pre_loss = 2.3863, BLEU-[2, 3, 4, 5] = [0.824, 0.536, 0.289, 0.158], NLL_gen = 2.3943, NLL_div = 2.5361, Self-BLEU-[2, 3, 4] = [0.846, 0.566, 0.315], [PPL-F, PPL-R] = 0
Starting Discriminator Training...
[MLE-DIS] d_step 0: d_loss = 0.0670, train_acc = 0.9780,
[MLE-DIS] d_step 1: d_loss = 0.0124, train_acc = 0.9969,
[MLE-DIS] d_step 2: d_loss = 0.0072, train_acc = 0.9981,
[MLE-DIS] d_step 3: d_loss = 0.0062, train_acc = 0.9982,
[MLE-DIS] d_step 4: d_loss = 0.0055, train_acc = 0.9984,
Starting Adversarial Training...
Initial generator: BLEU-[2, 3, 4, 5] = [0.825, 0.529, 0.272, 0.146], NLL_gen = 2.3943, NLL_div = 2.5229, Self-BLEU-[2, 3, 4] = [0.848, 0.569, 0.309], [PPL-F, PPL-R] = 0
-----
ADV EPOCH 0
-----
[ADV-GEN]: g_loss = 4685.4453, BLEU-[2, 3, 4, 5] = [0.83, 0.541, 0.297, 0.16], NLL_gen = 2.4101, NLL_div = 2.7479, Self-BLEU-[2, 3, 4] = [0.865, 0.605, 0.344], [PPL-F, PPL-R] = 0
[ADV-DIS] d_step 0: d_loss = 0.0137, train_acc = 0.9966,
[ADV-DIS] d_step 1: d_loss = 0.0114, train_acc = 0.9972,
[ADV-DIS] d_step 2: d_loss = 0.0120, train_acc = 0.9971,
[ADV-DIS] d_step 3: d_loss = 0.0115, train_acc = 0.9973,
-----
ADV EPOCH 1
-----
[ADV-GEN]: g_loss = 3376.2349, BLEU-[2, 3, 4, 5] = [0.83, 0.542, 0.291, 0.157], NLL_gen = 2.4312, NLL_div = 2.845, Self-BLEU-[2, 3, 4] = [0.873, 0.61, 0.361], [PPL-F, PPL-R] = 0
[ADV-DIS] d_step 0: d_loss = 0.0075, train_acc = 0.9981,
[ADV-DIS] d_step 1: d_loss = 0.0074, train_acc = 0.9981,
[ADV-DIS] d_step 2: d_loss = 0.0075, train_acc = 0.9982,
[ADV-DIS] d_step 3: d_loss = 0.0068, train_acc = 0.9983,
-----
ADV EPOCH 2
-----
>>> Stop by adv_signal! Finishing adversarial training...
